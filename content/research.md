---
title: Research
toc: true 
preamble: The core focus of MERGe Lab is **building better robots through intentional design of their bodies.** As robots are deployed outside of the lab and the factory, their bodies will need to match the wide variety of human environments. Our current suite of robot materials, structures, actuators and sensors are not adequate for human contact, let alone the wide range of environments that humans live in. {{< img src="img/thesisTree.png" alt="The core research of MERGe Lab is building sensors and actuators. This research draws on fundamentals of math, design studies, disability justice and materials science. It has applications in medical devices and robot manipulation" class="small-figure" >}} To address this need, MERGe Lab's key research strategy is to **design a material's geometry for robotic functionality**. Taking cues from developments in [mechanical metamaterials](https://en.wikipedia.org/wiki/Mechanical_metamaterial) / [architected materials](https://www.annualreviews.org/doi/10.1146/annurev-matsci-070115-031624), we recognize that designing a material's geometry has significant downstream effects on the material's mechanical behavior -- and, thus, the robot's end performance. This materials and geometry based approach has successfully created many unique and effective robot designs that are ripe for further computational optimization. <p></p> **Project List:**
---

# Active Projects

{{< img src="img/icra2024.png" alt="A sensorized robot gripper grasps a mustard bottle. It is sensorized through embedded air channels within the cubic lattice fingers." class="small-figure" >}}
## Blind Grasping

Current robots can do impressive grasping tasks with cameras and other forms of computer vision. However, humans are able to accomplish more dexterous manipulations without any vision, such as juggling or solving a Rubik's cube. There is a clear need to build the tactile sensors, end effectors and algorithms to imitate 

In this project, the goal is to have a robot be able to reach inside a box, fumble around, and eventually find an object inside without the use of cameras. This is a contact-rich task that will require identifying the box walls, searching for an unknown object and executing the optimal grasp to take it out of the box. With our past work in [fluidic innervation](https://www.science.org/doi/full/10.1126/sciadv.abq4385) and [object sensing](https://ieeexplore.ieee.org/abstract/document/8794098), we are confident not only in our ability to achieve this task, but also potentially solve grasping a specific object in clutter.

{{< img src="img/rhinoHSA.png" alt="Render of a handed shearing auxetic in the Rhino software" class="small-figure" >}}
## Computational Design with Sensorized Building Blocks
Using fluidic innervation as a technique to make larger structures

The idea behind this is the feeling that working primarily in lattices and their repeated geometry should offer some critical insight to the mathematics and modeling and make them easier to work with. 


{{< small_hr >}}

# Up-and-Coming Projects
Beyond our core research focus of building robotic sensors and actuators, we are also interested in: 
1. exploring the potential for new geometric designs
2. creating sensors and strategies that can enable contact-rich manipulation
3. applying these robotic devices for human-centered applications like co-design of accessibility technologies

Some potential projects in these directions include:

* Custom Sensorized Hands for Dexterous Manipulation
\[PICTURE COLLAGE OF ALL OF GREG'S FUNKY HANDS + MY MULTIPLEXED MANIPULATOR\]
I have a lot of ideas for funky hands to help the software manipulation folks do cool stuff. Basically, continuing the spirit of Greg further.

* Foldable mechanisms design
We will continue to explore new geometries for swarm robotics, medical applications, and robot manipulation

* Sensors for medical applications
\[PICTURE OF NIH WORK\]
In writing say particularly interested in phantoms

* Robots x Disability Justice
\[PICTURE OF NOTHING ABOUT US WITHOUT US FOR ROBOTS OR CO-DESIGN PICTURE FROM THAT PAPER CITED\]

{{< small_hr >}}

# Previous Projects

Our systems have [outperformed similar soft robots](https://dspace.mit.edu/bitstream/handle/1721.1/116908/Chin-2018-robosoft_HSA_hands.pdf?sequence=1&isAllowed=y) in power efficiency (20x more efficient) and speed (2x faster), [outperformed similar modular robots](https://ieeexplore.ieee.org/abstract/document/9976216) in locomotion (10x faster) while maintaining a high strength-weight ratio (76x), and [created the largest sensorized soft robotic dataset](https://www.science.org/doi/full/10.1126/sciadv.abq4385) (18 hours).

**Modular Volumetric Actuators (Auxbots)**

**Handed Shearing Auxetics (HSAs)**



