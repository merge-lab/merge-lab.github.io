<!doctype html><html lang=en-us><head><meta name=generator content="Hugo 0.120.3"><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=author content="Lilly Chin"><link rel=icon href=/favicon.png><title>Home | MERGe Lab</title>
<link rel=stylesheet href=/style.min.6ea017902f5bd9405d1b99c2906d9ecf9fd8885cfe25b613a64c5ebce9e6265c.css><link rel=stylesheet href=/fonts.min.f2be84683201ed3b3b7c8ca1ee0cd9ed6853907cc45eda7d24fc5829d3e440e8.css><script src=/rot13.min.ac65fd52f3ea0746e80f9c808c01237c4ba8739b18f44c10c61f2291b006e1e6.js></script></head><body><nav class=header><a href=/><img loading=lazy sizes="(min-width: 35em) 3000px, 400px, 100vw (max-width: 3000)" srcset='/img/bannerLarge_hu3c9acbf620b945beb3f4ce2c44c55633_83983_100x0_resize_box_3.png 200w
/img/bannerLarge_hu3c9acbf620b945beb3f4ce2c44c55633_83983_400x0_resize_box_3.png 400w
/img/bannerLarge_hu3c9acbf620b945beb3f4ce2c44c55633_83983_600x0_resize_box_3.png 600w
/img/bannerLarge_hu3c9acbf620b945beb3f4ce2c44c55633_83983_800x0_resize_box_3.png800w' src=/img/bannerLarge_hu3c9acbf620b945beb3f4ce2c44c55633_83983_600x0_resize_box_3.png alt='MERGe Lab banner image' style=margin:0></a><ul class=menu><li><a href=https://lillych.in>People</a></li><li><a href=https://lillych.in/research/>Research</a></li><li><a href=/publications/>Publications</a></li><li><a href=/news/>News</a></li><li><a href=/resources/>Resources</a></li></ul></nav><p></p><div class=home-txt><h2 id=about-the-lab>About The Lab</h2><p>Welcome to the homepage of the MERGe Lab, where we are working on making <strong>M</strong>aterials <strong>E</strong>mbody <strong>R</strong>obots, <strong>Ge</strong>ometrically. We are located at <a href=https://www.ece.utexas.edu>UT Austin&rsquo;s Electrical and Computer Engineering</a> department and led by Professor <a href=https://lillych.in>Lillian Chin</a>. We <em>merge</em> ideas across disciplines and see what interesting robots <em>emerge</em> as a result.</p><blockquote><p><strong>We are actively looking for graduate students and postdocs for the 2024-2025 school year.</strong> If interested, please apply directly to <a href=https://www.ece.utexas.edu/academics/graduate/admissions>UT Austin ECE</a>, listing Professor Lillian Chin&rsquo;s name, and <a href=https://litchin.wordpress.com/contact/>contact her directly</a> explaining what research interests we share. The more specific, the better!</p></blockquote><p>Our key research approach is <strong>designing a material&rsquo;s geometry for robotic functionality</strong>. Taking cues from developments in <a href=https://en.wikipedia.org/wiki/Mechanical_metamaterial>mechanical metamaterials</a> / <a href=https://www.annualreviews.org/doi/10.1146/annurev-matsci-070115-031624>architected materials</a>, we recognize that designing a material&rsquo;s geometry has significant downstream effects on the material&rsquo;s mechanical behavior &ndash; and, thus, the robot&rsquo;s end performance.</p><p>This materials and geometry based approach has been really effective in creating unique and effective robot designs. Our systems have <a href="https://dspace.mit.edu/bitstream/handle/1721.1/116908/Chin-2018-robosoft_HSA_hands.pdf?sequence=1&amp;isAllowed=y">outperformed similar soft robots</a> in power efficiency (20x more efficient) and speed (2x faster), <a href=https://ieeexplore.ieee.org/abstract/document/9976216>outperformed similar modular robots</a> in locomotion (10x faster) while maintaining a high strength-weight ratio (76x), and <a href=https://www.science.org/doi/full/10.1126/sciadv.abq4385>created the largest sensorized soft robotic dataset</a> (18 hours).</p><div style=text-align:center><video width=40% controls>
<source src=/img_static/auxbots.webm type=video/webm>Video of AuxBots moving forward in a mudskipper-style formation
</video>
<video width=40% controls>
<source src=/img_static/hsas.webm type=video/webm>Video of a 4 degree of freedom robotic platform built on handed shearing auxetics moving in all four degrees</video></div><p></p><p>Moving forward, we are interested in pursuing the following research directions:</p><ol><li>Design of novel actuators and sensors through geometry</li><li>Algorithmic frameworks to generate mechanisms for custom mechanical properties</li><li>Robot manipulation enhanced through accurate force and tactile sensing</li><li>Participatory design-based robot deployment in real-world communities</li></ol><div class=home-news><h2><a href=/news>Recent News:</a></h2><ul><li><strong>Nov. 2023</strong> &ndash; This website is online!</li><li><strong>Nov. 2023</strong> &ndash; Valerie, <a href=https://lillych.in>Lilly</a>, Jeana and <a href=https://www.annanzhang.com>Annan</a> submitted a paper to Robosoft 2024 on &ldquo;Online Packing of Groceries Through Soft Fingers with Integrated Visual-Tactile Sensing&rdquo;</li><li><strong>Sep. 2023</strong> &ndash; <a href=https://www.annanzhang.com>Annan</a> and <a href=https://lillych.in>Lilly</a> submitted a paper to ICRA 2024 on &ldquo;Embedded air channels transform soft lattices into sensorized grippers&rdquo;</li></ul></div></div><nav class=footer><hr><p class=text-muted style=float:left;text-align:left><small>Last updated: Nov 7, 2023</small></p><p class=text-muted style=float:right;text-align:right><small><img loading=lazy src=/icons8-mail-24.png alt="Email Icon" style=vertical-align:middle><span id=obfuscate>merge-labatutlistsdotutexasdotedu</span></small></p></nav><script>unobfuscate("obfuscate","<n uers='znvygb:zretr-yno@hgyvfgf.hgrknf.rqh'>zretr-yno@hgyvfgf.hgrknf.rqh</n>")</script></body></html>