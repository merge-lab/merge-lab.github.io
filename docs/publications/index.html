<!doctype html><html lang=en-us><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=author content="Lilly Chin"><link rel=icon href=/favicon.png><title>Publications | MERGe Lab</title>
<link rel=stylesheet href=/style.min.6ea017902f5bd9405d1b99c2906d9ecf9fd8885cfe25b613a64c5ebce9e6265c.css><link rel=stylesheet href=/fonts.min.f2be84683201ed3b3b7c8ca1ee0cd9ed6853907cc45eda7d24fc5829d3e440e8.css><script src=/rot13.min.ac65fd52f3ea0746e80f9c808c01237c4ba8739b18f44c10c61f2291b006e1e6.js></script></head><body><nav class=header><a href=/><img loading=lazy sizes="(min-width: 35em) 3000px, 400px, 100vw (max-width: 3000)" srcset='/img/bannerLarge_hu3c9acbf620b945beb3f4ce2c44c55633_83983_100x0_resize_box_3.png 200w
/img/bannerLarge_hu3c9acbf620b945beb3f4ce2c44c55633_83983_400x0_resize_box_3.png 400w
/img/bannerLarge_hu3c9acbf620b945beb3f4ce2c44c55633_83983_600x0_resize_box_3.png 600w
/img/bannerLarge_hu3c9acbf620b945beb3f4ce2c44c55633_83983_800x0_resize_box_3.png800w' src=/img/bannerLarge_hu3c9acbf620b945beb3f4ce2c44c55633_83983_600x0_resize_box_3.png alt='MERGe Lab banner image' style=margin:0></a><ul class=menu><li><a href=https://lillych.in>People</a></li><li><a href=https://lillych.in/research/>Research</a></li><li><a href=/publications/>Publications</a></li><li><a href=/news/>News</a></li><li><a href=/resources/>Resources</a></li></ul></nav><p></p><h1>Publications</h1><p>In all papers below, * means equal contribution to the manuscript. Members of the lab have been underlined. Notable papers have been <span class=highlight>highlighted</span>.</p><p>For the most up-to-date list of publications, please check Professor Chin&rsquo;s <a href="https://scholar.google.com/citations?hl=en&amp;user=yPvT_i4AAAAJ&amp;view_op=list_works&amp;sortby=pubdate">Google Scholar profile</a>.</p><blockquote><p><strong>This page is under construction.</strong> Please refer to the Google Scholar page while summaries are being uploaded.</p></blockquote><hr><table><col span=1 style=width:20%><col span=1 style=width:80%><tr><td><a href=/img_static/zhang2023machine.png><img src=/img_static/zhang2023machine.png alt="Machine learning for soft robot proprioception should match the data distribution and sensor inputs" style=margin:0></a></td><td><strong>Machine Learning Best Practices for Soft Robot Proprioception</strong><br>Annan Zhang*, Tsun-Hsuan Wang*, Ryan L. Truby, <u>Lillian Chin</u>, Daniela Rus<br><em>IROS 2023</em><br><a href=https://www.annanzhang.com/data/pdf/zhang2023machine.pdf>Paper</a><br><br>Based on experiments on two large soft robotics datasets, we derive best practices for training neural networks that map sensor signals to soft robot shape.</td></tr><tr><td><a href=/img_static/zhang2022vision.jpg><img src=/img_static/zhang2022vision.jpg alt="Cameras are placed at the top of the handed shearing auxetic fingers to view internal state changes" style=margin:0></a></td><td><strong>Vision-Based Sensing for Electrically-Driven Soft Actuators</strong><br>Annan Zhang, Ryan L. Truby, <u>Lillian Chin</u>, Shuguang Li, Daniela Rus<br><em>IEEE RA-L</em>, 2022. Also presented at IROS 2022.<br><a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=9866780">Paper</a><br><br>We use cameras to record the interior of compliant electric actuators and train a neural network that maps the visual feedback to the actuator&rsquo;s tip pose. Our method presents a robust approach for sensorizing hollow-bodied actuators and provides accurate predictions in the presence of external disturbances.</td></tr><tr class=highlight><td><a href=/img_static/truby2022fluidic.png><img src=/img_static/truby2022fluidic.png alt="See-through rendered view of a lattice, showing internal fluid chambers" style=margin:0></a></td><td><strong>Fluidic Innervation Sensorizes Structures from a Single Build Material</strong><br>Ryan L. Truby*, <u>Lillian Chin*</u>, Annan Zhang, Daniela Rus<br><em>Science Advances</em>, 2022<br><a href=https://www.science.org/doi/pdf/10.1126/sciadv.abq4385>Paper</a> | <a href=https://news.mit.edu/2022/materials-sense-movements-0810>MIT News</a><br><br>We embed air-filled channels within architected materials and measure the pressure change during deformation. Our method integrates programmed mechanical behavior, sensing, and actuation and enables sensorized structures for wearables and robotics from one single build material.</td></tr></table><nav class=footer><hr><p class=text-muted style=float:left;text-align:left><small>Last updated: Nov 7, 2023</small></p><p class=text-muted style=float:right;text-align:right><small><img loading=lazy src=/icons8-mail-24.png alt="Email Icon" style=vertical-align:middle><span id=obfuscate>merge-labatutlistsdotutexasdotedu</span></small></p></nav><script>unobfuscate("obfuscate","<n uers='znvygb:zretr-yno@hgyvfgf.hgrknf.rqh'>zretr-yno@hgyvfgf.hgrknf.rqh</n>")</script></body></html>